{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ML_Logistic Regression_Assignment\n",
        "\n",
        "Question 1:  What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "Goal: Logistic â†’ classify (probability of class), Linear â†’ predict continuous value.\n",
        "\n",
        "Model: Logistic uses\n",
        "ð‘\n",
        "(\n",
        "ð‘¦\n",
        "=\n",
        "1\n",
        "âˆ£\n",
        "ð‘¥\n",
        ")\n",
        "=\n",
        "ðœŽ\n",
        "(\n",
        "ð‘¤\n",
        "âŠ¤\n",
        "ð‘¥\n",
        "+\n",
        "ð‘\n",
        ")\n",
        "p(y=1âˆ£x)=Ïƒ(w\n",
        "âŠ¤\n",
        " x+b) with sigmoid; Linear uses\n",
        "ð‘¦\n",
        "^\n",
        "=\n",
        "ð‘¤\n",
        "âŠ¤\n",
        "ð‘¥\n",
        "+\n",
        "ð‘\n",
        "y\n",
        "^\n",
        "â€‹\n",
        " =w\n",
        "âŠ¤\n",
        " x+b.\n",
        "\n",
        "Loss: Logistic uses log-loss (maximum likelihood); Linear commonly uses MSE.\n",
        "\n",
        "Output: Logistic in\n",
        "[\n",
        "0\n",
        ",\n",
        "1\n",
        "]\n",
        "[0,1] â†’ threshold to label; Linear unbounded.\n",
        "\n",
        "Assumptions: Logistic assumes log-odds are linear in features."
      ],
      "metadata": {
        "id": "g-gXB9mG6_oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "\n",
        "Maps any real-valued score to a probability:\n",
        "ðœŽ\n",
        "(\n",
        "ð‘§\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ð‘’\n",
        "âˆ’\n",
        "ð‘§\n",
        "Ïƒ(z)=\n",
        "1+e\n",
        "âˆ’z\n",
        "\n",
        "1\n",
        "â€‹\n",
        " , with\n",
        "ð‘§\n",
        "=\n",
        "ð‘¤\n",
        "âŠ¤\n",
        "ð‘¥\n",
        "+\n",
        "ð‘\n",
        "z=w\n",
        "âŠ¤\n",
        " x+b.\n",
        "\n",
        "Monotonic â†’ preserves ranking; differentiable â†’ enables gradient-based optimization.\n",
        "\n",
        "Decision rule: predict 1 if\n",
        "ðœŽ\n",
        "(\n",
        "ð‘§\n",
        ")\n",
        "â‰¥\n",
        "ðœ\n",
        "Ïƒ(z)â‰¥Ï„ (often\n",
        "ðœ\n",
        "=\n",
        "0.5\n",
        "Ï„=0.5)."
      ],
      "metadata": {
        "id": "uYsplSGW7arP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "Adds a penalty on coefficients to control model complexity and prevent overfitting.\n",
        "\n",
        "L2 (Ridge):\n",
        "ðœ†\n",
        "âˆ¥\n",
        "ð‘¤\n",
        "âˆ¥\n",
        "2\n",
        "2\n",
        "Î»âˆ¥wâˆ¥\n",
        "2\n",
        "2\n",
        "â€‹\n",
        "  â†’ shrinks weights smoothly; handles multicollinearity.\n",
        "\n",
        "L1 (Lasso):\n",
        "ðœ†\n",
        "âˆ¥\n",
        "ð‘¤\n",
        "âˆ¥\n",
        "1\n",
        "Î»âˆ¥wâˆ¥\n",
        "1\n",
        "â€‹\n",
        "  â†’ drives some weights to zero (feature selection).\n",
        "\n",
        "Hyperparameter C (in sklearn) is inverse of regularization strength (\n",
        "ð¶\n",
        "â†‘\n",
        "â‡’\n",
        "Câ†‘â‡’ weaker reg)."
      ],
      "metadata": {
        "id": "zz4ogu2k7aoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are some common evaluation metrics for classification models, and why are they important?\n",
        "\n",
        "Common evaluation metrics for classification & why they matter\n",
        "Accuracy: overall correctness; can mislead on imbalanced data.\n",
        "\n",
        "Precision / Recall / F1: handle class imbalance; F1 balances P & R.\n",
        "\n",
        "ROC-AUC: ranking quality across thresholds; good for balanced or when costs similar.\n",
        "\n",
        "PR-AUC: better when positives are rare.\n",
        "\n",
        "Confusion matrix: shows TP/FP/TN/FN to diagnose errors."
      ],
      "metadata": {
        "id": "ao4Zn-zX7alz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "w8lSfxdB7ajH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "clf = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, clf.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUzSVOJm7o0D",
        "outputId": "6caab4dc-b446-46e7-f8b3-868df4b55d4c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6:  Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy.\n",
        "\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "8wfAd6q_7agN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Coefficients shape:\", clf.coef_.shape)\n",
        "print(\"First 5 coefficients:\", clf.coef_[0][:5])\n",
        "print(\"Intercept:\", clf.intercept_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, clf.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xehqSGNf8omU",
        "outputId": "98224f58-b66c-4b06-9661-1f48ef5cdbd9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients shape: (1, 30)\n",
            "First 5 coefficients: [ 1.93035716e+00  7.14564675e-02 -5.03933094e-02 -1.69573330e-03\n",
            " -1.45563995e-01]\n",
            "Intercept: [0.36481037]\n",
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.\n",
        "\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "UkHkIVCs7acz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "clf = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7IUFLRk9Bl_",
        "outputId": "1db6de8d-510e-48cf-bc75-2643cc9b48c6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.90      0.95        10\n",
            "           2       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy.\n",
        "\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "VwLkHNhM7aZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "candidates = [(p, C) for p in ['l1', 'l2'] for C in [0.01, 0.1, 1, 10]]\n",
        "best, best_params = -1, None\n",
        "for penalty, C in candidates:\n",
        "    clf = LogisticRegression(solver='liblinear', penalty=penalty, C=C, max_iter=1000, random_state=42)\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    score = accuracy_score(y_val, clf.predict(X_val))\n",
        "    if score > best: best, best_params = score, {'penalty': penalty, 'C': C}\n",
        "print(\"Best Params:\", best_params)\n",
        "print(\"Validation Accuracy:\", round(best, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BibiLDxD9Kx3",
        "outputId": "9ccc35b8-b4d8-420d-ce82-d338f195627a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'penalty': 'l2', 'C': 10}\n",
            "Validation Accuracy: 0.9556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.\n",
        "\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "AidIN5SA9MIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7, stratify=y)\n",
        "\n",
        "plain = LogisticRegression(max_iter=1000, solver='liblinear', random_state=7).fit(X_train, y_train)\n",
        "acc_plain = accuracy_score(y_test, plain.predict(X_test))\n",
        "\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('logreg', LogisticRegression(max_iter=1000, solver='liblinear', random_state=7))]).fit(X_train, y_train)\n",
        "acc_scaled = accuracy_score(y_test, pipe.predict(X_test))\n",
        "\n",
        "print(\"Without scaling:\", round(acc_plain, 4))\n",
        "print(\"With scaling:\", round(acc_scaled, 4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br6myNrL7ZgB",
        "outputId": "a348e3cd-819b-484b-8dda-4a1bab9d6f03"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without scaling: 0.9333\n",
            "With scaling: 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach youâ€™d take to build a Logistic Regression model â€” including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
        "use case."
      ],
      "metadata": {
        "id": "erVJ7KC-9Mk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data split & leakage control: Stratified train/val/test; keep\n",
        "\n",
        "campaign-time order if temporal.\n",
        "\n",
        "Preprocess: Handle missing values; one-hot encode categoricals; cap/transform skewed features; remove leakage features.\n",
        "\n",
        "Scaling: Standardize numeric features (especially with regularization).\n",
        "\n",
        "Class imbalance:\n",
        "\n",
        "Use class_weight='balanced' (built-in) and/or resampling (e.g., SMOTE on train only).\n",
        "\n",
        "Consider threshold tuning to hit desired recall/precision or business uplift.\n",
        "\n",
        "Hyperparameters: Tune C, penalty (L1/L2), solver; try interaction terms or monotonic bins.\n",
        "\n",
        "Metrics: Favor PR-AUC, Recall@k, Precision/Recall/F1, calibrated Brier score; report confusion matrix.\n",
        "\n",
        "Calibration: Platt/Isotonic for well-calibrated probabilities â†’ better targeting.\n",
        "\n",
        "Explainability: Coefficients (sign/magnitude) or SHAP for stakeholder trust.\n",
        "\n",
        "Deployment: Choose threshold by ROI curve (cost per contact vs expected uplift); monitor drift and re-train on fresh data."
      ],
      "metadata": {
        "id": "ytCBZu039feG"
      }
    }
  ]
}