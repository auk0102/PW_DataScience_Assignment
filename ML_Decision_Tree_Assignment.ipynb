{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ML_Decision Tree_Assignment"
      ],
      "metadata": {
        "id": "20FfD-zmHZtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  What is a Decision Tree, and how does it work in the context of classification?"
      ],
      "metadata": {
        "id": "61dwoDXJH5l5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree is a flowchart-like model that splits data into subsets based on feature values. Each internal node represents a decision, branches represent outcomes, and leaf nodes give the final class label. It works by repeatedly splitting the data into purer groups until a stopping condition is reached."
      ],
      "metadata": {
        "id": "xtXW32M0J7i_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?"
      ],
      "metadata": {
        "id": "Gff6ptAxIN2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both are measures of how mixed a node is.\n",
        "\n",
        "1. Gini Impurity measures the chance of misclassifying an item.\n",
        "\n",
        "2. Entropy measures the level of uncertainty in a node.\n",
        "Lower values mean purer nodes. The tree chooses splits that reduce impurity the most, leading to better class separation."
      ],
      "metadata": {
        "id": "Xcf7aMhVJ9Ed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each."
      ],
      "metadata": {
        "id": "pxT2f0JHIR_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pre-Pruning: Stop tree growth early using limits like max depth or minimum samples. Advantage → saves time and prevents overfitting.\n",
        "\n",
        "2. Post-Pruning: Grow the full tree first, then remove weak branches. Advantage → often gives a simpler, more generalizable model."
      ],
      "metadata": {
        "id": "zFQ3pcF3KI3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?"
      ],
      "metadata": {
        "id": "400gXTHBIR3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Gain is the improvement in purity after a split. It shows how useful a feature is for classification. The split with the highest gain is chosen, ensuring the tree makes the most informative decisions."
      ],
      "metadata": {
        "id": "bfZyT4jPKQDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?"
      ],
      "metadata": {
        "id": "YVZpPoHFIRwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Applications: credit scoring, medical diagnosis, churn prediction, fraud detection.\n",
        "\n",
        "2. Advantages: simple to interpret, handles categorical & numerical, no scaling needed.\n",
        "\n",
        "3. Limitations: prone to overfitting, unstable (small data changes → different tree), less accurate than ensembles."
      ],
      "metadata": {
        "id": "z-VRAU_3KaK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Info:\n",
        "\n",
        "● Iris Dataset for classification tasks (sklearn.datasets.load_iris() or provided CSV).\n",
        "\n",
        "● Boston Housing Dataset for regression tasks\n",
        "(sklearn.datasets.load_boston() or provided CSV).\n",
        "\n",
        "Question 6:   Write a Python program to:\n",
        "\n",
        "● Load the Iris Dataset\n",
        "\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "\n",
        "● Print the model’s accuracy and feature importances\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "m4JRosV3IRtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "print(\"Feature importances:\", clf.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MHMjIsAUKeuf",
        "outputId": "242bc2cb-275e-4767-cdca-999de224b21f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9333333333333333\n",
            "Feature importances: [0.00625    0.02916667 0.5585683  0.40601504]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7:  Write a Python program to:\n",
        "\n",
        "● Load the Iris Dataset\n",
        "\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree.\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "ysb7tiiZIRqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_full = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\n",
        "clf_d3 = DecisionTreeClassifier(max_depth=3, random_state=42).fit(X_train, y_train)\n",
        "\n",
        "print(\"Full Tree Acc:\", accuracy_score(y_test, clf_full.predict(X_test)))\n",
        "print(\"Depth=3 Acc:\", accuracy_score(y_test, clf_d3.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TZlYnbbeLXSO",
        "outputId": "f4f678f9-60ab-4461-a50f-c5546b164280"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Tree Acc: 0.9333333333333333\n",
            "Depth=3 Acc: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "\n",
        "● Load the Boston Housing Dataset\n",
        "\n",
        "● Train a Decision Tree Regressor\n",
        "\n",
        "● Print the Mean Squared Error (MSE) and feature importances\n",
        "\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "rUx_UJRlIRnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Assume X_train, X_test, y_train, y_test already split\n",
        "reg = DecisionTreeRegressor(random_state=42).fit(X_train, y_train)\n",
        "print(\"MSE:\", mean_squared_error(y_test, reg.predict(X_test)))\n",
        "print(\"Feature importances:\", reg.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UeKY3TtULyPX",
        "outputId": "5ec52979-583a-4c30-82cf-c5fffbed09d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.06666666666666667\n",
            "Feature importances: [0.003125   0.01458333 0.77928415 0.20300752]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "\n",
        "● Load the Iris Dataset\n",
        "\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using GridSearchCV\n",
        "\n",
        "● Print the best parameters and the resulting model accuracy\n",
        "\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "Yp9p2KHDIRkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'max_depth':[2,3,4,None],'min_samples_split':[2,4,6]}\n",
        "grid = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
        "grid.fit(X, y)\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "M6CIR5lIL2kT",
        "outputId": "d64a2c33-20f2-4841-b6b8-982e32a6e47f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'max_depth': 3, 'min_samples_split': 2}\n",
            "Best Accuracy: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        " Explain the step-by-step process you would follow to:\n",
        "\n",
        "● Handle the missing values\n",
        "\n",
        "● Encode the categorical features\n",
        "\n",
        "● Train a Decision Tree model\n",
        "\n",
        "● Tune its hyperparameters\n",
        "\n",
        "● Evaluate its performance\n",
        "\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting."
      ],
      "metadata": {
        "id": "JG6-Dg9eIRhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "**In an imbalanced marketing dataset (only 5% positive):**\n",
        "\n",
        "Data handling: Clean missing values, encode categoricals, remove leakage.\n",
        "\n",
        "Scaling: Standardize numeric features.\n",
        "\n",
        "Balancing classes: Use class weights or resampling (e.g., SMOTE).\n",
        "\n",
        "Model training: Logistic Regression with regularization.\n",
        "\n",
        "Hyperparameter tuning: Adjust C and penalty using cross-validation.\n",
        "\n",
        "Evaluation: Use precision, recall, F1, and PR-AUC instead of accuracy.\n",
        "Business value: Helps target the right customers, reduces marketing cost, and improves campaign effectiveness.\n",
        "\n",
        "\n",
        "**And for disease prediction in healthcare:**\n",
        "\n",
        "Handle missing values: Impute with mean/median for numeric, mode for categorical.\n",
        "\n",
        "Encode categorical features: Use label or one-hot encoding.\n",
        "\n",
        "Train model: Decision Tree Classifier, possibly with balanced class weights.\n",
        "\n",
        "Hyperparameter tuning: Optimize depth, splits, and criteria using GridSearchCV.\n",
        "\n",
        "Evaluation: Use recall, precision, F1, and ROC-AUC to ensure reliable detection.\n",
        "Business value: Enables early disease detection, supports doctors in decision-making, reduces costs, and improves patient outcomes."
      ],
      "metadata": {
        "id": "r9kO3F4PNOPD"
      }
    }
  ]
}